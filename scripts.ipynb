{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tulime network analysis\n",
    "\n",
    "The data regarding the project was first obtained through an Gsheet compiled partially by an organization component and partially by me, employing the data provided by the association thrugh mails and Whatsapp conversations. <br>\n",
    "This sheet served, once completed, to extract data regarding single projects and convert them into CSVs in order to later access them through python and perform analysis and operation on data through <a href=\"https://pandas.pydata.org/\">Pandas</a> library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_in_dir(dir):\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f) and f[-4:] == \".csv\":\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all the random integers for the beneficiaris of Maji in Pomerini, Kitowo and Mwawambala were extracted.<br>\n",
    "A corresponding number of rows was added to the excel file with \"Name*n*\" in the \"NAME\" field and the village name in the corresponding one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_kitowo=random.randint(2500, 3000)\n",
    "rand_pomerini=random.randint(850, 900)\n",
    "rand_mwawambala=random.randint(850, 900)\n",
    "\n",
    "df_maji = pd.DataFrame(index=np.arange(rand_kitowo+rand_pomerini+rand_mwawambala), columns=[\"NAME\", \"VILLAGE\", \"AGE\", \"SEX\", \"FAMILY\", \"START\"])\n",
    "idx = df_maji.index.values.astype(int)\n",
    "idx = idx [1:]\n",
    "for el in idx:\n",
    "    df_maji.loc[el, \"NAME\"] = \"Name\"+str(el)\n",
    "    if el in range(1, rand_kitowo):\n",
    "        df_maji.loc[el, \"VILLAGE\"] = \"Kitowo\"\n",
    "    elif el in range(rand_kitowo, rand_kitowo+rand_pomerini):\n",
    "        df_maji.loc[el, \"VILLAGE\"] = \"Pomerini\"\n",
    "    elif el in range(rand_kitowo+rand_pomerini, rand_kitowo+rand_pomerini+rand_mwawambala):\n",
    "        df_maji.loc[el, \"VILLAGE\"] = \"Mawambala\"\n",
    "df_maji=df_maji.dropna(thresh=2)\n",
    "#df_maji.to_csv(r\"projects_csv/Maji.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first step we need to obtain the distribution of values absent in other CSVs from the that present a more complete amount of information. To do so we first of all extract the data we have and organize it in dictionaries (to conver in CSVs) containing the values of interest and the numbre of peope in realtion to each of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv\")]\n",
    "\n",
    "sex_dict = dict()\n",
    "age_dict=dict()\n",
    "age_dict_children = dict()\n",
    "family_dict=dict()\n",
    "\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df=df.fillna(\"NaN\")\n",
    "    for col in df.columns:\n",
    "        if col == \"SEX\":\n",
    "            for el in df[col]:\n",
    "                if el in sex_dict.keys():\n",
    "                    sex_dict[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    sex_dict[el]=1\n",
    "\n",
    "        if col == \"AGE\" and file not in [\"projects_csv\\TupoPamoja.csv\", \"projects_csv\\PiantalaSubito.csv\"]:\n",
    "            for el in df[col]:\n",
    "                if el in age_dict.keys():\n",
    "                    age_dict[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    age_dict[el]=1\n",
    "\n",
    "        if col== \"AGE\":\n",
    "            for el in df[col]:\n",
    "                if el in age_dict_children.keys():\n",
    "                    age_dict_children[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    age_dict_children[el]=1\n",
    "\n",
    "        \n",
    "        if col == \"FAMILY\":\n",
    "            for el in df[col]:\n",
    "                if el in family_dict.keys():\n",
    "                    family_dict[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    family_dict[el]=1\n",
    "\n",
    "df_sex = pd.DataFrame.from_dict(sex_dict, orient='index')\n",
    "#df_sex.to_csv(r\"projects_csv/measures/sex_count.csv\")\n",
    "\n",
    "age_dict = dict(sorted(age_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age = pd.DataFrame.from_dict(age_dict, orient='index')\n",
    "#df_age.to_csv(r\"projects_csv/measures/age_count.csv\")\n",
    "\n",
    "age_dict_children = dict(sorted(age_dict_children.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age_children = pd.DataFrame.from_dict(age_dict_children, orient='index')\n",
    "#df_age_children.to_csv(r\"projects_csv/measures/agetotal_count.csv\")\n",
    "\n",
    "family_dict = dict(sorted(family_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_family = pd.DataFrame.from_dict(family_dict, orient='index')\n",
    "#df_family.to_csv(r\"projects_csv/measures/family_count.csv\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns were then renaimed as \"*VARIABLE*\" and \"PEOPLE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting distributions from the values obtained\n",
    "In order to fill missing gaps in the other CSVs we need to transform the data already in our possess into distributions of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sex = 0\n",
    "sum_age = 0\n",
    "sum_agechildren = 0\n",
    "sum_family = 0\n",
    "\n",
    "for el in sex_dict.keys():\n",
    "    sum_sex += sex_dict[el]\n",
    "for el in sex_dict.keys():\n",
    "    sex_dict[el]=sex_dict[el]/sum_sex\n",
    "\n",
    "for el in age_dict.keys():\n",
    "    sum_age += age_dict[el]\n",
    "for el in age_dict.keys():\n",
    "    age_dict[el]=age_dict[el]/sum_age\n",
    "\n",
    "for el in age_dict_children.keys():\n",
    "    sum_agechildren += age_dict_children[el]\n",
    "for el in age_dict_children.keys():\n",
    "    age_dict_children[el]=age_dict_children[el]/sum_agechildren\n",
    "\n",
    "for el in family_dict.keys():\n",
    "    sum_family += family_dict[el]\n",
    "for el in family_dict.keys():\n",
    "    family_dict[el]=family_dict[el]/sum_family\n",
    "\n",
    "df_sex = pd.DataFrame.from_dict(sex_dict, orient='index')\n",
    "#df_sex.to_csv(r\"projects_csv/measures/sex_distribution.csv\")\n",
    "\n",
    "age_dict = dict(sorted(age_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age = pd.DataFrame.from_dict(age_dict, orient='index')\n",
    "#df_age.to_csv(r\"projects_csv/measures/age_distribution.csv\")\n",
    "\n",
    "age_dict_children = dict(sorted(age_dict_children.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age_children = pd.DataFrame.from_dict(age_dict_children, orient='index')\n",
    "#df_age_children.to_csv(r\"projects_csv/measures/agetotal_distribution.csv\")\n",
    "\n",
    "family_dict = dict(sorted(family_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_family = pd.DataFrame.from_dict(family_dict, orient='index')\n",
    "#df_family.to_csv(r\"projects_csv/measures/family_distribution.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns were then renaimed as \"*VARIABLE*\" and \"PERCENTAGE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values in CSVs using obtained distributions\n",
    "Now we need to use those values to fill missing cells in the remaining CSVs. WE will care about exceptions such as TupoPamoja and Mwalimu, that have restricted age range and consider the total age CSV just for MAJI, which is a project devoted to water supply: this could seem an uneveness in balance, since children are high in number but one of te interventions of MAJI regards only the school district, that by itself counts 900 inhabitants of younger ages with respect to other villagers. <br>\n",
    "In order to do so <a href=\"https://numpy.org/doc/stable/\">Numpy</a> was employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv\")]\n",
    "\n",
    "df_age = pd.read_csv(\"projects_csv/measures/age_distribution.csv\")\n",
    "df_age_total = pd.read_csv(\"projects_csv/measures/agetotal_distribution.csv\")\n",
    "df_sex = pd.read_csv(\"projects_csv/measures/sex_distribution.csv\")\n",
    "df_family = pd.read_csv(\"projects_csv/measures/family_distribution.csv\")\n",
    "\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    missing_age = df[\"AGE\"].isnull()\n",
    "    missing_sex = df[\"SEX\"].isnull()\n",
    "    missing_family = df[\"FAMILY\"].isnull()\n",
    "    if file.split(\"\\\\\")[1] not in [\"Maji.csv\", \"Mwalimu.csv\", \"TupoPamoja.csv\"]:\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(df_age[\"AGE\"], size=len(df[missing_age]), p=df_age[\"PERCENTAGE\"])\n",
    "    elif file.split(\"\\\\\")[1] not in [\"TupoPamoja.csv\", \"Mwalimu.csv\"]:\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(df_age_total[\"AGE\"], size=len(df[missing_age]), p=df_age_total[\"PERCENTAGE\"])\n",
    "    df.loc[missing_sex, \"SEX\"] = np.random.choice(df_sex[\"SEX\"], size=len(df[missing_sex]), p=df_sex[\"PERCENTAGE\"])\n",
    "    df.loc[missing_family, \"FAMILY\"] = np.random.choice(df_family[\"FAMILY\"], size=len(df[missing_family]), p=df_family[\"PERCENTAGE\"])\n",
    "    if file.split(\"\\\\\")[1] == \"TupoPamoja.csv\":\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(range(18, 49, 6), size=len(df[missing_age]))\n",
    "        for row in df.iterrows():\n",
    "            age = row[1][\"AGE\"]\n",
    "            idx = df[df['AGE']==age].index.values.astype(int)[0]\n",
    "            new_age = float(\"{:.2f}\".format(age/12))\n",
    "            df.loc[idx, \"AGE\"] = new_age\n",
    "    elif file.split(\"\\\\\")[1] == \"Mwalimu.csv\":\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(range(18, 25), size=len(df[missing_age]))\n",
    "   \n",
    "    #df.to_csv(r\"projects_csv/complete/complete_\"+file.split(\"\\\\\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "After qualitative judgement of some data it was noticed that some names were reported differently from CSV to CSV and so a cleaning was required. <br>\n",
    "Projects that reported participants, outside villages described by the association were restricted to Mi.Fi.Ma. and the small amount of paticipants (less than 15) residing outside Pomerini were registered as Pomerinians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/complete\")]\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    idx = df.index.values.astype(int)\n",
    "    for el in idx:\n",
    "        if df.loc[el, \"VILLAGE\"] == \"Kihesa Mgagao\":\n",
    "            df.loc[el, \"VILLAGE\"] = \"Khesa Mgagao\"\n",
    "        if df.loc[el, \"VILLAGE\"] in [\"Kaole\", \"Iringa\", \"Mbeya\", \"Lukani\", \"Ilula\", \"Ilula (Ikokoto)\", \"Image\", \"Dabaga\", \"Itungi\"]:\n",
    "            df.loc[el, \"VILLAGE\"] = \"Pomerini\"\n",
    "    #df.to_csv(r\"projects_csv/complete/\"+file.split(\"\\\\\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Villages complete files\n",
    "In order to represent the brader villages environment, random graphs were generated in Gephi: this was also done basing on the information given from the association and corresponds to their averaging of the population.<br>\n",
    "The villages under consideration were:\n",
    "<ol>\n",
    "<li><b>Khesa Mgagao</b>: ca. 2000 inhabitants </li>\n",
    "<li><b>Kitowo</b>: ca. 3000 inhabitants </li>\n",
    "<li><b>Mwawambala</b>: ca. 3000 inhabitants </li>\n",
    "<li><b>Pomerini</b>: ca. 3000 inhabitants </li>\n",
    "<li><b>Ukumbi</b>: ca. 3000 inhabitants </li>\n",
    "</ol>\n",
    "\n",
    "Basing on the information provided by the association, the oscillation in population and their unawareness of the real number of villagers, the number of inhabitants was set in a range of +- 250 around their averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_kitowo=random.randint(2750, 3250)\n",
    "rand_ukumbi=random.randint(2750, 3250)\n",
    "rand_mwawambala=random.randint(2750, 3250)\n",
    "rand_pomerini=random.randint(2750, 3250)\n",
    "rand_khesa_mgagao=random.randint(1750, 2250)\n",
    "\n",
    "id=0\n",
    "\n",
    "age_df=pd.read_csv(\"projects_csv/measures\\\\age_count.csv\", encoding=\"utf-8\")\n",
    "agetotal_df=pd.read_csv(\"projects_csv/measures\\\\agetotal_count.csv\", encoding=\"utf-8\")\n",
    "age_total_df = pd.concat([age_df,agetotal_df],ignore_index=True)\n",
    "idx = age_total_df.index.values.astype(int)\n",
    "total_age = age_total_df['PEOPLE'].sum() \n",
    "for el in idx:\n",
    "    age_total_df.loc[el, \"PEOPLE\"] = age_total_df.loc[el, \"PEOPLE\"]/total_age\n",
    "\n",
    "\n",
    "village_dict = {\"Kitowo\": rand_kitowo, \"Khesa Mgagao\": rand_khesa_mgagao, \"Mawambala\": rand_mwawambala, \"Pomerini\": rand_pomerini, \"Ukumbi\": rand_ukumbi}\n",
    "\n",
    "for village in village_dict.keys():\n",
    "    df=pd.DataFrame(index=np.arange(village_dict[village]), columns=[\"ID\",\"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"VILLAGE\"])\n",
    "    idx = df.index.values.astype(int)\n",
    "    missing_age = df[\"AGE\"].isnull()\n",
    "    missing_family=df[\"FAMILY\"].isnull()\n",
    "    missing_sex=df[\"SEX\"].isnull()\n",
    "    missing_id = df[\"ID\"].isnull()\n",
    "    df.loc[missing_age,'AGE'] = np.random.choice(age_total_df[\"AGE\"], size=len(df[missing_age]),p=age_total_df[\"PEOPLE\"] )\n",
    "    df.loc[missing_sex, \"SEX\"] = np.random.choice([\"M\", \"F\"], size=len(df[missing_sex]))\n",
    "    df.loc[missing_family, \"FAMILY\"] = np.random.choice(df_family[\"FAMILY\"], size=len(df[missing_family]), p=df_family[\"PERCENTAGE\"])\n",
    "    for el in idx[1:]:\n",
    "        df.loc[el, \"NAME\"] = \"Name\"+str(el)\n",
    "        df.loc[el, \"ID\"] = id+el\n",
    "        df.loc[el, \"VILLAGE\"] = village\n",
    "    df=df.dropna(thresh=4)\n",
    "    id=id+village_dict[village]-1\n",
    "    \n",
    "    #df.to_csv(r\"projects_csv/complete/complete_\"+village+\".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the villages networks we can simply extract the data from the projects CSVs and substitute random generated rows with the ones belonging to projects set in that village. <br> \n",
    "In this way we will obtain a description of the situation for each village but, since what we want is a wider view on the project's influence on the community not only in villages but as a cross bridge between them, we ought to generate a complete network of Tulims's influence in the Pomerini zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/complete\")]\n",
    "villages = list()\n",
    "projects = list()\n",
    "for file in to_scan:\n",
    "    if file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0] in [\"Pomerini\", \"Mawambala\", \"Kitowo\", \"Khesa Mgagao\", \"Ukumbi\"]:\n",
    "        villages.append(file)\n",
    "    else:\n",
    "        projects.append(file)\n",
    "\n",
    "idx_dict = {\"Kitowo\": 1, \"Khesa Mgagao\": 1, \"Mawambala\": 1, \"Pomerini\": 1, \"Ukumbi\": 1}\n",
    "\n",
    "for project in projects:\n",
    "    df_project = pd.read_csv(project, encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "    project_name = project.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    idx = df_project.index.values.astype(int)\n",
    "    for el in idx:\n",
    "        village = df_project.loc[el, \"VILLAGE\"]\n",
    "        try:\n",
    "            df_village = pd.read_csv(\"projects_csv/complete/complete_\"+village+\".csv\", encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "            df_village.loc[idx_dict[village], \"NAME\"] = df_project.loc[el, \"NAME\"]\n",
    "            df_village.loc[idx_dict[village], \"VILLAGE\"] = df_project.loc[el, \"VILLAGE\"]\n",
    "            df_village.loc[idx_dict[village], \"PROJECT\"] = project_name\n",
    "            df_village.loc[idx_dict[village], \"AGE\"] = df_project.loc[el, \"AGE\"]\n",
    "            df_village.loc[idx_dict[village], \"SEX\"] = df_project.loc[el, \"SEX\"]\n",
    "            df_village.loc[idx_dict[village], \"FAMILY\"] = df_project.loc[el, \"FAMILY\"]\n",
    "            df_village.loc[idx_dict[village], \"START\"] = df_project.loc[el, \"START\"]\n",
    "            #df_village.to_csv(r\"projects_csv/complete/complete_\"+village+\".csv\")\n",
    "            idx_dict[village]+=1\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can mesh up those networks and create a wider one containing all information regarding projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/complete\")]\n",
    "villages = list()\n",
    "for file in to_scan:\n",
    "    if file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0] in [\"Pomerini\", \"Mawambala\", \"Kitowo\", \"Khesa Mgagao\", \"Ukumbi\"]:\n",
    "        villages.append(file)\n",
    "\n",
    "df_total=pd.DataFrame(columns=[\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"VILLAGE\"])\n",
    "\n",
    "for village in villages:\n",
    "    village_name = village.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    df = pd.read_csv(village, encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "    df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "    missing_village=df_total[\"VILLAGE\"].isnull()\n",
    "    df_total.loc[missing_village, \"VILLAGE\"] = village_name\n",
    "\n",
    "#df_total.to_csv(r\"projects_csv/complete/whole_network.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can manually migrate files in a dedicated folder, namely \"villages\" and set the id as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df=df.set_index(\"ID\")\n",
    "    #df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating village networks\n",
    "Now, in order to create our network we need to set rules in order to discretely decide if two nodes are connected. <br>\n",
    "The main discriminants would be: \n",
    "<ol>\n",
    "<li><b>Being part of the same project</b>: this should be the most valuable kind of connection, of weight 3, since what we are trying to investigate are the connections created by the projects; </li>\n",
    "<li><b>Being part of the same family</b>: this kind of connection has definitely a heavier weight, since people living in the same family core should exchange information and positive or negative reinforcements that can weight on project's efficience; </li>\n",
    "<li><b>Being part of the same village</b></li>\n",
    "</ol>\n",
    "\n",
    "So now every node should present:\n",
    " <ol>\n",
    "<li>A number of connection of <b>weight 2</b> equal to the <b>number of participants in its project minus one</b> (itself)</li>\n",
    "<li>A number of connection of <b>weight 1</b> equal to the <b>number of people in its family core</b></li>\n",
    "</ol>\n",
    "\n",
    "Also in this phase it was possible to balance incoherences in family components distribution: simply after a first cycle of edges is created it is possible that some names are still present in the starting dataset.<br>\n",
    "This is because it is very difficult for families to be distributed so that at the end every component is in a core: the problem was solved by grouping leftovers as if they were a family core on their own of size equal to their quantity. Anyway it is impossible that this quantity exceeds the maximum amount of people per family, because otherway some of them would group together and lower again the quantity below 8, which is the maximum width of family cores.<br>\n",
    "This new family core is not only included as a set of edges but substituted to the previous in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df = df.sample(frac=1, ignore_index=True)\n",
    "\n",
    "    df_network = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "    df_node = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "\n",
    "    if file != \"projects_csv/villages\\\\whole_network.csv\":\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        idx = df.index.values.astype(int)\n",
    "        name_list = list()\n",
    "        for el in idx:\n",
    "            try:\n",
    "                n=1\n",
    "                for el_2 in idx:\n",
    "                    if n<=int(df.loc[el, \"FAMILY\"]):\n",
    "                        if df.loc[el, \"FAMILY\"] == df.loc[el_2, \"FAMILY\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"]:\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            family_count = int(df.loc[el, \"FAMILY\"])\n",
    "                            n+=1\n",
    "                            df = df.drop(el_2)\n",
    "                            idx = df.index.values.astype(int)\n",
    "                        else:\n",
    "                            continue     \n",
    "                    else:\n",
    "                        idx_last_edge = len(df_network)-1\n",
    "                        for i in range(family_count):\n",
    "                            target_count=family_count-(i+1)\n",
    "                            c=1\n",
    "                            for z in range(target_count):\n",
    "                                pointer_source = idx_last_edge-i\n",
    "                                pointer = pointer_source-c\n",
    "                                df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                c+=1\n",
    "                        df = df.drop(el)\n",
    "                        idx = df.index.values.astype(int)\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "\n",
    "        if len(df)>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx[:1]:\n",
    "                name_list.append(df.loc[el, \"ID\"])\n",
    "                for el_2 in idx[1:]:\n",
    "                    df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                    df_network = pd.concat([df_network, df_node], ignore_index = True)\n",
    "                    family_count = int(df.loc[el, \"FAMILY\"])\n",
    "                    name_list.append(df.loc[el_2, \"ID\"])\n",
    "                    df = df.drop(el_2)\n",
    "            idx_last_edge = len(df_network)-1\n",
    "            for i in range(family_count):\n",
    "                target_count=family_count-(i+1)\n",
    "                c=1\n",
    "                for z in range(target_count):\n",
    "                    pointer_source = idx_last_edge-i\n",
    "                    pointer = pointer_source-c\n",
    "                    df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                    df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                    c+=1\n",
    "            df = df.drop(el)\n",
    "        \n",
    "\n",
    "        df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        df_whole = pd.read_csv(\"projects_csv/villages\\\\whole_network.csv\", encoding=\"utf-8\")\n",
    "\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            if df.loc[el, \"ID\"] in name_list:\n",
    "                name = df.loc[el, \"ID\"]\n",
    "                df.loc[el, \"FAMILY\"] = len(name_list)\n",
    "                idx_name = df_whole.index[(df_whole[\"ID\"] == name) & (df_whole[\"VILLAGE\"] == file_name)]\n",
    "                df_whole.loc[idx_name, \"FAMILY\"] = len(name_list)\n",
    "        \n",
    "        #df.to_csv(r\"projects_csv/villages/complete_\"+file_name+\".csv\")\n",
    "\n",
    "        df_whole = df_whole.set_index('ID')\n",
    "        #df_whole.to_csv(r\"projects_csv/villages\\\\whole_network.csv\")\n",
    "\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            try:\n",
    "                project_count = 0\n",
    "                if df.loc[el, \"PROJECT\"] != \"Maji\":\n",
    "                    for el_2 in idx[el:]:\n",
    "                        if df.loc[el, \"PROJECT\"] == df.loc[el_2, \"PROJECT\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"]:\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            project_count +=1\n",
    "                            df = df.drop(el_2) \n",
    "                        else:\n",
    "                            continue        \n",
    "                    idx_last_edge = len(df_network)-1\n",
    "                    for i in range(project_count):\n",
    "                        target_count=project_count-(i+1)\n",
    "                        c=1\n",
    "                        for z in range(target_count):\n",
    "                            pointer_source = idx_last_edge-i\n",
    "                            pointer = pointer_source-c\n",
    "                            df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                            df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                            c+=1\n",
    "                    df = df.drop(el)\n",
    "            except Exception as e:\n",
    "                continue        \n",
    "\n",
    "        #df_network.to_csv(r\"projects_csv/networks/\"+file_name+\"_edges.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a file containing edges of the whole network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/networks\")]\n",
    "df_whole_edges = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df_whole_edges = pd.concat([df_whole_edges, df], ignore_index=True)\n",
    "\n",
    "df=pd.read_csv(\"projects_csv/villages\\\\whole_network.csv\", encoding=\"utf-8\")\n",
    "idx = df.index.values.astype(int)\n",
    "for el in idx:\n",
    "    try:\n",
    "        project_count = 0\n",
    "        if df.loc[el, \"PROJECT\"] != \"Maji\":\n",
    "            for el_2 in idx[el:]:\n",
    "                if df.loc[el, \"PROJECT\"] == df.loc[el_2, \"PROJECT\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"] and df.loc[el, \"VILLAGE\"] != df.loc[el_2, \"VILLAGE\"]:\n",
    "                    df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                    df_whole_edges = pd.concat([df_whole_edges, df_node],ignore_index=True)\n",
    "                    project_count +=1\n",
    "                    df = df.drop(el_2) \n",
    "                else:\n",
    "                    continue        \n",
    "            idx_last_edge = len(df_whole_edges)-1\n",
    "            for i in range(project_count):\n",
    "                target_count=project_count-(i+1)\n",
    "                c=1\n",
    "                for z in range(target_count):\n",
    "                    pointer_source = idx_last_edge-i\n",
    "                    pointer = pointer_source-c\n",
    "                    df_node.loc[1,\"SOURCE\"] = df_whole_edges.loc[pointer_source, \"TARGET\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df_whole_edges.loc[pointer, \"TARGET\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                    df_whole_edges = pd.concat([df_whole_edges, df_node], ignore_index=True)\n",
    "                    c+=1\n",
    "            df = df.drop(el)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "df_whole_edges = df_whole_edges.drop_duplicates(keep='last')\n",
    "#df_whole_edges.to_csv(r\"projects_csv/networks/whole_edges.csv\")              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing left to do is clean the data as to process it in Gephi, by removing empty cells. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "for file in to_scan:\n",
    "    file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    try:\n",
    "        df= df.drop(\"Unnamed: 0\", axis=1)\n",
    "    except Exception:\n",
    "        df[[\"AGE\", \"FAMILY\", \"START\"]] = df[[\"AGE\", \"FAMILY\", \"START\"]].apply(pd.to_numeric)\n",
    "        df.to_csv(r\"projects_csv/networks/\"+file_name+\"_nodes.csv\")\n",
    "    df[[\"AGE\", \"FAMILY\", \"START\"]] = df[[\"AGE\", \"FAMILY\", \"START\"]].apply(pd.to_numeric)\n",
    "    #df.to_csv(r\"projects_csv/networks/\"+file_name+\"_nodes.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the new files and the nwtworks are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/networks\")]\n",
    "for file in to_scan:\n",
    "    file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    if file_name == \"edges\": \n",
    "        df = df.set_index(\"SOURCE\")\n",
    "    else:\n",
    "        df = df.set_index(\"ID\")\n",
    "    try: \n",
    "        df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "        #df.to_csv(file)\n",
    "    except Exception:\n",
    "        #df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data regarding friends and working relatioship\n",
    " \n",
    "Another possible approach is to use literature on this topic to extract data regarding significant communities such as friendship and co-working. <br>\n",
    "\n",
    "In \"The role of strong-tie social networks in mediating food security of fish\n",
    "resources by a traditional riverine community in the Brazilian Amazon\" (2015, F. Merthes et al.) communities based on friendship have been find to fall in a range from 2 to 29 nodes connected; also work communities fall in a similar range, from 2 to 30. In the study it was found that, upon 915 that came down to 793 when considering overlappings, relationships, 177 were of friendship kind, 167 of working type and 571 based on kinship.<br>\n",
    "\n",
    "From this data, and the distribution of kinship relationship we have at disposal, we can easily recreate a model that follows the distribution evidentiated in this study and fills the gaps created by missing edge weights. This model should present nodes with edges strctured as follows:\n",
    " <ol>\n",
    "<li>A number of connection of <b>weight 2</b> equal to the <b>number of participants in its project minus one</b> (itself)</li>\n",
    "<li>A number of connection of <b>weight 1</b> equal to the <b>number of people in its family core</b> plus the <b>number of people in its friends and co-working community minus one</b> (itself)</li>\n",
    "</ol> \n",
    "\n",
    "Some small corrections were carried on in random assignation of value: irst of all children do not work, so their value of relationship through work was set to 0 and second no one has no friends so, in case available ties ended a random value between 1 and 3 was extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GIORGI~1\\AppData\\Local\\Temp/ipykernel_25260/110126752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mto_add\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"WORK\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"WORK\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mdf_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_add\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;31m#filling work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4905\u001b[0m         \"\"\"\n\u001b[1;32m-> 4906\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4185\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4186\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4188\u001b[0m         \u001b[1;31m# Case for non-unique axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4771\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4772\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4774\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4817\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4818\u001b[1;33m         return self._reindex_axes(\n\u001b[0m\u001b[0;32m   4819\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4820\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4595\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"index\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4596\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4597\u001b[1;33m             frame = frame._reindex_index(\n\u001b[0m\u001b[0;32m   4598\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4599\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4611\u001b[0m         \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4612\u001b[0m     ):\n\u001b[1;32m-> 4613\u001b[1;33m         new_index, indexer = self.index.reindex(\n\u001b[0m\u001b[0;32m   4614\u001b[0m             \u001b[0mnew_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4615\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   3823\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3824\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3825\u001b[1;33m                     indexer = self.get_indexer(\n\u001b[0m\u001b[0;32m   3826\u001b[0m                         \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3827\u001b[0m                     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3484\u001b[0m             )\n\u001b[0;32m   3485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3488\u001b[0m     def _get_indexer(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3510\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_nearest_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3511\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3512\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_engine_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3514\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "to_scan = [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "\n",
    "for file in to_scan:\n",
    "    if file != \"projects_csv/villages\\\\whole_network.csv\":\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        df = pd.read_csv(\"projects_csv/networks/\"+file_name+\"_edges.csv\", encoding=\"utf-8\")\n",
    "        conversion_factor = df[\"WEIGHT\"].value_counts()[1]/571\n",
    "        friendship_ties = np.floor(177*conversion_factor)\n",
    "        working_ties = np.floor(167*conversion_factor)\n",
    "\n",
    "        df = pd.read_csv(file, encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "        df = df.sample(frac=1, ignore_index=True)\n",
    "        df[\"FRIENDS\"] = np.nan\n",
    "        df[\"WORK\"] = np.nan\n",
    "        df_nowork = df.index[(df['PROJECT'] == \"TupoPamoja\") | (df['PROJECT'] == \"PiantalaSubito\")]\n",
    "        df.loc[df_nowork,'WORK'] = 0\n",
    "        missing_friends = df[\"FRIENDS\"].isnull()\n",
    "        df.loc[missing_friends,'FRIENDS'] = np.random.choice(range(2, 29), size=len(df[missing_friends]))\n",
    "        missing_work = df[\"WORK\"].isnull()\n",
    "        df.loc[missing_work,'WORK'] = np.random.choice(range(2, 30), size=len(df[missing_work]))\n",
    "\n",
    "        df_network = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "        df_node = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "        df_nodes = pd.DataFrame(columns = [\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"FRIENDS\", \"WORK\"])\n",
    "        to_add = pd.DataFrame(columns = [\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"FRIENDS\", \"WORK\"])\n",
    "\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            try:\n",
    "                n=1\n",
    "                for el_2 in idx: \n",
    "                    if n<=int(df.loc[el, \"FRIENDS\"]):\n",
    "                        if df.loc[el, \"FRIENDS\"] == df.loc[el_2, \"FRIENDS\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"] and friendship_ties>0:\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = df.loc[el_2, \"FRIENDS\"]\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                            df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            friends_count = int(df.loc[el, \"FRIENDS\"])\n",
    "                            n+=1\n",
    "                            df = df.drop(el_2)\n",
    "                            idx = df.index.values.astype(int)\n",
    "                        elif friendship_ties<=0:\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = random.randint(1,3)\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                            df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                            break     \n",
    "                    elif friendship_ties>0:\n",
    "                        to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                        to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                        to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                        to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                        to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                        to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                        to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                        to_add.loc[1, \"FRIENDS\"] = df.loc[el, \"FRIENDS\"]\n",
    "                        to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                        df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                        idx_last_edge = len(df_network)-1\n",
    "                        for i in range(friends_count):\n",
    "                            friendship_ties = friendship_ties-(friends_count-i)\n",
    "                            target_count=friends_count-(i+1)\n",
    "                            c=1\n",
    "                            for z in range(target_count):\n",
    "                                pointer_source = idx_last_edge-i\n",
    "                                pointer = pointer_source-c\n",
    "                                df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                c+=1\n",
    "                        df = df.drop(el)\n",
    "                        idx = df.index.values.astype(int)\n",
    "                        break\n",
    "                    else:\n",
    "                        to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                        to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                        to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                        to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                        to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                        to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                        to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                        to_add.loc[1, \"FRIENDS\"] = random.randint(1,3)\n",
    "                        to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                        df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        if len(df)>0 and friendship_ties>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx:\n",
    "                try:\n",
    "                    n=1\n",
    "                    for el_2 in idx: \n",
    "                        if n<=len(df):\n",
    "                            if df.loc[el, \"FRIENDS\"] == df.loc[el_2, \"FRIENDS\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"] and working_ties>0:\n",
    "                                to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                                to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                                to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                                to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                                to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                                to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                                to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                                to_add.loc[1, \"FRIENDS\"] = df.loc[el_2, \"FRIENDS\"]\n",
    "                                to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                                df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                                df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                                friends_count = int(df.loc[el, \"FRIENDS\"])\n",
    "                                n+=1\n",
    "                                df = df.drop(el_2)\n",
    "                                idx = df.index.values.astype(int)\n",
    "                            elif friendship_ties<=0:\n",
    "                                to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                                to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                                to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                                to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                                to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                                to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                                to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                                to_add.loc[1, \"FRIENDS\"] = random.randint(1,3)\n",
    "                                to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                                df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                                break     \n",
    "                        elif friendship_ties>0:\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = df.loc[el, \"FRIENDS\"]\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                            df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                            idx_last_edge = len(df_network)-1\n",
    "                            for i in range(friends_count):\n",
    "                                friendship_ties = friendship_ties-(friends_count-i)\n",
    "                                target_count=friends_count-(i+1)\n",
    "                                c=1\n",
    "                                for z in range(target_count):\n",
    "                                    pointer_source = idx_last_edge-i\n",
    "                                    pointer = pointer_source-c\n",
    "                                    df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                    df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                    df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                    c+=1\n",
    "                            df = df.drop(el)\n",
    "                            idx = df.index.values.astype(int)\n",
    "                            break\n",
    "                        else:\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        elif len(df)>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx:\n",
    "                to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                to_add.loc[1, \"FRIENDS\"] = random.randint(1,3)\n",
    "                to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                df = df.drop(el)\n",
    "\n",
    "        #filling work\n",
    "\n",
    "        df = df_nodes       \n",
    "        df = df.sample(frac=1, ignore_index=True)\n",
    "\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            try:\n",
    "                n=1\n",
    "                for el_2 in idx:\n",
    "                    if n<=int(df.loc[el, \"WORK\"]): \n",
    "                        if df.loc[el, \"WORK\"] == df.loc[el_2, \"WORK\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"] and working_ties>0:\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = df.loc[el_2, \"FRIENDS\"]\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                            df_nodes = pd.concat([df_nodes, to_add], ignore_index=True)\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            work_count = int(df.loc[el, \"WORK\"])\n",
    "                            n+=1\n",
    "                            df = df.drop(el_2)\n",
    "                            idx = df.index.values.astype(int)\n",
    "                        elif working_ties<=0:\n",
    "                            id_to_look = df.loc[el_2, \"ID\"]\n",
    "                            df_nodes.loc[id_to_look, \"WORK\"] = 0  \n",
    "                            break\n",
    "                    elif working_ties>0:\n",
    "                        idx_last_edge = len(df_network)-1\n",
    "                        for i in range(work_count):\n",
    "                            working_ties = working_ties-(work_count-i)\n",
    "                            target_count=work_count-(i+1)\n",
    "                            c=1\n",
    "                            for z in range(target_count):\n",
    "                                pointer_source = idx_last_edge-i\n",
    "                                pointer = pointer_source-c\n",
    "                                df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                c+=1\n",
    "                        df = df.drop(el)\n",
    "                        idx = df.index.values.astype(int)\n",
    "                        break\n",
    "                    else:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "\n",
    "        if len(df)>0 and working_ties>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx:\n",
    "                try:\n",
    "                    n=1\n",
    "                    for el_2 in idx: \n",
    "                        if n<=len(df):\n",
    "                            if df.loc[el, \"WORK\"] == df.loc[el_2, \"WORK\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"] and working_ties>0:\n",
    "                                to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                                to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                                to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                                to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                                to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                                to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                                to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                                to_add.loc[1, \"FRIENDS\"] = df.loc[el_2, \"FRIENDS\"]\n",
    "                                to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                                df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                                df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                                work_count = int(df.loc[el, \"FRIENDS\"])\n",
    "                                n+=1\n",
    "                                df = df.drop(el_2)\n",
    "                                idx = df.index.values.astype(int)\n",
    "                            elif working_ties<0:\n",
    "                                id_to_look = df.loc[el_2, \"ID\"]\n",
    "                                df_nodes.loc[id_to_look, \"WORK\"] = 0\n",
    "                                break     \n",
    "                        elif working_ties>0:\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = df.loc[el, \"FRIENDS\"]\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                            df_nodes = pd.concat([df_nodes, to_add],ignore_index=True)\n",
    "                            idx_last_edge = len(df_network)-1\n",
    "                            for i in range(work_count):\n",
    "                                working_ties = working_ties-(work_count-i)\n",
    "                                target_count=work_count-(i+1)\n",
    "                                c=1\n",
    "                                for z in range(target_count):\n",
    "                                    pointer_source = idx_last_edge-i\n",
    "                                    pointer = pointer_source-c\n",
    "                                    df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                    df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                    df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                    c+=1\n",
    "                            df = df.drop(el)\n",
    "                            idx = df.index.values.astype(int)\n",
    "                            break\n",
    "                        else:\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        elif len(df)>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx:\n",
    "                id_to_look = df.loc[el, \"ID\"]\n",
    "                df_nodes.loc[id_to_look, \"WORK\"] = 0\n",
    "\n",
    "            \n",
    "\n",
    "        df_nodes = df_nodes.drop_duplicates(keep=\"last\")\n",
    "        df_nodes = df_nodes.set_index(\"ID\")\n",
    "        df_nodes.to_csv(r\"projects_csv/villages_comparison/nodes_\"+file_name+\".csv\")\n",
    "\n",
    "        df_to_concat = pd.read_csv(\"projects_csv/networks\\\\\"+ file_name+\"_edges.csv\", encoding=\"utf-8\")\n",
    "        df_network = pd.concat([df_network, df_to_concat], ignore_index=True)\n",
    "        #df_network = df_network.drop(\"Unnamed: 0\")\n",
    "        df_network = df_network.set_index(\"SOURCE\")\n",
    "        \n",
    "        df_network.to_csv(r\"projects_csv/villages_comparison/edges_\"+file_name+\".csv\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "Now we can close up with the data cleaning: setting data type to columns and substituting blank values with spaces to make files readable from Gephi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GIORGI~1\\AppData\\Local\\Temp/ipykernel_25260/1944487978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ID\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"AGE\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5813\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5814\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5815\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5816\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m         \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mastype_float_to_int_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \"\"\"\n\u001b[0;32m   1212\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         raise IntCastingNaNError(\n\u001b[0m\u001b[0;32m   1214\u001b[0m             \u001b[1;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         )\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "to_clean = [file for file in get_all_in_dir(\"projects_csv/villages_comparison\")]\n",
    "for file in to_clean:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\") \n",
    "    for col in df.columns:\n",
    "        if col == \"ID\" or col == \"AGE\":\n",
    "            df[col] =  df[col].astype(int)\n",
    "        else:\n",
    "            df = df.astype({col: str})\n",
    "    df.to_csv(file)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to create the whole network of villages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giorgia Sampo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (2,5,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_whole = pd.read_csv(\"projects_csv/networks\\\\whole_edges.csv\", encoding=\"utf-8\")\n",
    "df_whole_nodes = pd.DataFrame(columns = [\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"FRIENDS\", \"WORK\"])\n",
    "to_append = [file for file in get_all_in_dir(\"projects_csv/villages_comparison\")]\n",
    "for file in to_append:\n",
    "    file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    if file_name == \"edges\":\n",
    "        df_to_append = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        df_whole = pd.concat([df_whole,df_to_append], ignore_index=True)\n",
    "    else:\n",
    "        df_to_append = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        df_whole_nodes = pd.concat([df_whole_nodes, df_to_append], ignore_index=True)\n",
    "\n",
    "df_whole.to_csv(r\"projects_csv/villages_comparison/network_edges.csv\")\n",
    "df_whole_nodes.to_csv(r\"projects_csv/villages_comparison/network_nodes.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d603ae3e84bc2c7668b84db465d2afb033d38d826ce98f701f29ef4e883b1f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
