{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tulime network analysis\n",
    "\n",
    "The data regarding the project was first obtained through an Gsheet compiled partially by an organization component and partially by me, employing the data provided by the association thrugh mails and Whatsapp conversations. <br>\n",
    "This sheet served, once completed, to extract data regarding single projects and convert them into CSVs in order to later access them through python and perform analysis and operation on data through <a href=\"https://pandas.pydata.org/\">Pandas</a> library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_in_dir(dir):\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f) and f[-4:] == \".csv\":\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all the random integers for the beneficiaris of Maji in Pomerini, Kitowo and Mwawambala were extracted.<br>\n",
    "A corresponding number of rows was added to the excel file with \"Name*n*\" in the \"NAME\" field and the village name in the corresponding one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_kitowo=random.randint(2500, 3000)\n",
    "rand_pomerini=random.randint(850, 900)\n",
    "rand_mwawambala=random.randint(850, 900)\n",
    "\n",
    "df_maji = pd.DataFrame(index=np.arange(rand_kitowo+rand_pomerini+rand_mwawambala), columns=[\"NAME\", \"VILLAGE\", \"AGE\", \"SEX\", \"FAMILY\", \"START\"])\n",
    "idx = df_maji.index.values.astype(int)\n",
    "idx = idx [1:]\n",
    "for el in idx:\n",
    "    df_maji.loc[el, \"NAME\"] = \"Name\"+str(el)\n",
    "    if el in range(1, rand_kitowo):\n",
    "        df_maji.loc[el, \"VILLAGE\"] = \"Kitowo\"\n",
    "    elif el in range(rand_kitowo, rand_kitowo+rand_pomerini):\n",
    "        df_maji.loc[el, \"VILLAGE\"] = \"Pomerini\"\n",
    "    elif el in range(rand_kitowo+rand_pomerini, rand_kitowo+rand_pomerini+rand_mwawambala):\n",
    "        df_maji.loc[el, \"VILLAGE\"] = \"Mawambala\"\n",
    "df_maji=df_maji.dropna(thresh=2)\n",
    "#df_maji.to_csv(r\"projects_csv/Maji.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first step we need to obtain the distribution of values absent in other CSVs from the that present a more complete amount of information. To do so we first of all extract the data we have and organize it in dictionaries (to conver in CSVs) containing the values of interest and the numbre of peope in realtion to each of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv\")]\n",
    "\n",
    "sex_dict = dict()\n",
    "age_dict=dict()\n",
    "age_dict_children = dict()\n",
    "family_dict=dict()\n",
    "\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df=df.fillna(\"NaN\")\n",
    "    for col in df.columns:\n",
    "        if col == \"SEX\":\n",
    "            for el in df[col]:\n",
    "                if el in sex_dict.keys():\n",
    "                    sex_dict[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    sex_dict[el]=1\n",
    "\n",
    "        if col == \"AGE\" and file not in [\"projects_csv\\TupoPamoja.csv\", \"projects_csv\\PiantalaSubito.csv\"]:\n",
    "            for el in df[col]:\n",
    "                if el in age_dict.keys():\n",
    "                    age_dict[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    age_dict[el]=1\n",
    "\n",
    "        if col== \"AGE\":\n",
    "            for el in df[col]:\n",
    "                if el in age_dict_children.keys():\n",
    "                    age_dict_children[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    age_dict_children[el]=1\n",
    "\n",
    "        \n",
    "        if col == \"FAMILY\":\n",
    "            for el in df[col]:\n",
    "                if el in family_dict.keys():\n",
    "                    family_dict[el]+=1\n",
    "                elif el !=\"NaN\":\n",
    "                    family_dict[el]=1\n",
    "\n",
    "df_sex = pd.DataFrame.from_dict(sex_dict, orient='index')\n",
    "#df_sex.to_csv(r\"projects_csv/measures/sex_count.csv\")\n",
    "\n",
    "age_dict = dict(sorted(age_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age = pd.DataFrame.from_dict(age_dict, orient='index')\n",
    "#df_age.to_csv(r\"projects_csv/measures/age_count.csv\")\n",
    "\n",
    "age_dict_children = dict(sorted(age_dict_children.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age_children = pd.DataFrame.from_dict(age_dict_children, orient='index')\n",
    "#df_age_children.to_csv(r\"projects_csv/measures/agetotal_count.csv\")\n",
    "\n",
    "family_dict = dict(sorted(family_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_family = pd.DataFrame.from_dict(family_dict, orient='index')\n",
    "#df_family.to_csv(r\"projects_csv/measures/family_count.csv\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns were then renaimed as \"*VARIABLE*\" and \"PEOPLE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting distributions from the values obtained\n",
    "In order to fill missing gaps in the other CSVs we need to transform the data already in our possess into distributions of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sex = 0\n",
    "sum_age = 0\n",
    "sum_agechildren = 0\n",
    "sum_family = 0\n",
    "\n",
    "for el in sex_dict.keys():\n",
    "    sum_sex += sex_dict[el]\n",
    "for el in sex_dict.keys():\n",
    "    sex_dict[el]=sex_dict[el]/sum_sex\n",
    "\n",
    "for el in age_dict.keys():\n",
    "    sum_age += age_dict[el]\n",
    "for el in age_dict.keys():\n",
    "    age_dict[el]=age_dict[el]/sum_age\n",
    "\n",
    "for el in age_dict_children.keys():\n",
    "    sum_agechildren += age_dict_children[el]\n",
    "for el in age_dict_children.keys():\n",
    "    age_dict_children[el]=age_dict_children[el]/sum_agechildren\n",
    "\n",
    "for el in family_dict.keys():\n",
    "    sum_family += family_dict[el]\n",
    "for el in family_dict.keys():\n",
    "    family_dict[el]=family_dict[el]/sum_family\n",
    "\n",
    "df_sex = pd.DataFrame.from_dict(sex_dict, orient='index')\n",
    "#df_sex.to_csv(r\"projects_csv/measures/sex_distribution.csv\")\n",
    "\n",
    "age_dict = dict(sorted(age_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age = pd.DataFrame.from_dict(age_dict, orient='index')\n",
    "#df_age.to_csv(r\"projects_csv/measures/age_distribution.csv\")\n",
    "\n",
    "age_dict_children = dict(sorted(age_dict_children.items(), key=lambda item: item[1], reverse=True))\n",
    "df_age_children = pd.DataFrame.from_dict(age_dict_children, orient='index')\n",
    "#df_age_children.to_csv(r\"projects_csv/measures/agetotal_distribution.csv\")\n",
    "\n",
    "family_dict = dict(sorted(family_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "df_family = pd.DataFrame.from_dict(family_dict, orient='index')\n",
    "#df_family.to_csv(r\"projects_csv/measures/family_distribution.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns were then renaimed as \"*VARIABLE*\" and \"PERCENTAGE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values in CSVs using obtained distributions\n",
    "Now we need to use those values to fill missing cells in the remaining CSVs. WE will care about exceptions such as TupoPamoja and Mwalimu, that have restricted age range and consider the total age CSV just for MAJI, which is a project devoted to water supply: this could seem an uneveness in balance, since children are high in number but one of te interventions of MAJI regards only the school district, that by itself counts 900 inhabitants of younger ages with respect to other villagers. <br>\n",
    "In order to do so <a href=\"https://numpy.org/doc/stable/\">Numpy</a> was employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv\")]\n",
    "\n",
    "df_age = pd.read_csv(\"projects_csv/measures/age_distribution.csv\")\n",
    "df_age_total = pd.read_csv(\"projects_csv/measures/agetotal_distribution.csv\")\n",
    "df_sex = pd.read_csv(\"projects_csv/measures/sex_distribution.csv\")\n",
    "df_family = pd.read_csv(\"projects_csv/measures/family_distribution.csv\")\n",
    "\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    missing_age = df[\"AGE\"].isnull()\n",
    "    missing_sex = df[\"SEX\"].isnull()\n",
    "    missing_family = df[\"FAMILY\"].isnull()\n",
    "    if file.split(\"\\\\\")[1] not in [\"Maji.csv\", \"Mwalimu.csv\", \"TupoPamoja.csv\"]:\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(df_age[\"AGE\"], size=len(df[missing_age]), p=df_age[\"PERCENTAGE\"])\n",
    "    elif file.split(\"\\\\\")[1] not in [\"TupoPamoja.csv\", \"Mwalimu.csv\"]:\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(df_age_total[\"AGE\"], size=len(df[missing_age]), p=df_age_total[\"PERCENTAGE\"])\n",
    "    df.loc[missing_sex, \"SEX\"] = np.random.choice(df_sex[\"SEX\"], size=len(df[missing_sex]), p=df_sex[\"PERCENTAGE\"])\n",
    "    df.loc[missing_family, \"FAMILY\"] = np.random.choice(df_family[\"FAMILY\"], size=len(df[missing_family]), p=df_family[\"PERCENTAGE\"])\n",
    "    if file.split(\"\\\\\")[1] == \"TupoPamoja.csv\":\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(range(18, 49, 6), size=len(df[missing_age]))\n",
    "        for row in df.iterrows():\n",
    "            age = row[1][\"AGE\"]\n",
    "            idx = df[df['AGE']==age].index.values.astype(int)[0]\n",
    "            new_age = float(\"{:.2f}\".format(age/12))\n",
    "            df.loc[idx, \"AGE\"] = new_age\n",
    "    elif file.split(\"\\\\\")[1] == \"Mwalimu.csv\":\n",
    "        df.loc[missing_age, \"AGE\"] = np.random.choice(range(18, 25), size=len(df[missing_age]))\n",
    "   \n",
    "    #df.to_csv(r\"projects_csv/complete/complete_\"+file.split(\"\\\\\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "After qualitative judgement of some data it was noticed that some names were reported differently from CSV to CSV and so a cleaning was required. <br>\n",
    "Projects that reported participants, outside villages described by the association were restricted to Mi.Fi.Ma. and the small amount of paticipants (less than 15) residing outside Pomerini were registered as Pomerinians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/complete\")]\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    idx = df.index.values.astype(int)\n",
    "    for el in idx:\n",
    "        if df.loc[el, \"VILLAGE\"] == \"Kihesa Mgagao\":\n",
    "            df.loc[el, \"VILLAGE\"] = \"Khesa Mgagao\"\n",
    "        if df.loc[el, \"VILLAGE\"] in [\"Kaole\", \"Iringa\", \"Mbeya\", \"Lukani\", \"Ilula\", \"Ilula (Ikokoto)\", \"Image\", \"Dabaga\", \"Itungi\"]:\n",
    "            df.loc[el, \"VILLAGE\"] = \"Pomerini\"\n",
    "    #df.to_csv(r\"projects_csv/complete/\"+file.split(\"\\\\\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Villages complete files\n",
    "In order to represent the brader villages environment, random graphs were generated in Gephi: this was also done basing on the information given from the association and corresponds to their averaging of the population.<br>\n",
    "The villages under consideration were:\n",
    "<ol>\n",
    "<li><b>Khesa Mgagao</b>: ca. 2000 inhabitants </li>\n",
    "<li><b>Kitowo</b>: ca. 3000 inhabitants </li>\n",
    "<li><b>Mwawambala</b>: ca. 3000 inhabitants </li>\n",
    "<li><b>Pomerini</b>: ca. 3000 inhabitants </li>\n",
    "<li><b>Ukumbi</b>: ca. 3000 inhabitants </li>\n",
    "</ol>\n",
    "\n",
    "Basing on the information provided by the association, the oscillation in population and their unawareness of the real number of villagers, the number of inhabitants was set in a range of +- 250 around their averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_kitowo=random.randint(2750, 3250)\n",
    "rand_ukumbi=random.randint(2750, 3250)\n",
    "rand_mwawambala=random.randint(2750, 3250)\n",
    "rand_pomerini=random.randint(2750, 3250)\n",
    "rand_khesa_mgagao=random.randint(1750, 2250)\n",
    "\n",
    "id=0\n",
    "\n",
    "age_df=pd.read_csv(\"projects_csv/measures\\\\age_count.csv\", encoding=\"utf-8\")\n",
    "agetotal_df=pd.read_csv(\"projects_csv/measures\\\\agetotal_count.csv\", encoding=\"utf-8\")\n",
    "age_total_df = pd.concat([age_df,agetotal_df],ignore_index=True)\n",
    "idx = age_total_df.index.values.astype(int)\n",
    "total_age = age_total_df['PEOPLE'].sum() \n",
    "for el in idx:\n",
    "    age_total_df.loc[el, \"PEOPLE\"] = age_total_df.loc[el, \"PEOPLE\"]/total_age\n",
    "\n",
    "\n",
    "village_dict = {\"Kitowo\": rand_kitowo, \"Khesa Mgagao\": rand_khesa_mgagao, \"Mawambala\": rand_mwawambala, \"Pomerini\": rand_pomerini, \"Ukumbi\": rand_ukumbi}\n",
    "\n",
    "for village in village_dict.keys():\n",
    "    df=pd.DataFrame(index=np.arange(village_dict[village]), columns=[\"ID\",\"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"VILLAGE\"])\n",
    "    idx = df.index.values.astype(int)\n",
    "    missing_age = df[\"AGE\"].isnull()\n",
    "    missing_family=df[\"FAMILY\"].isnull()\n",
    "    missing_sex=df[\"SEX\"].isnull()\n",
    "    missing_id = df[\"ID\"].isnull()\n",
    "    df.loc[missing_age,'AGE'] = np.random.choice(age_total_df[\"AGE\"], size=len(df[missing_age]),p=age_total_df[\"PEOPLE\"] )\n",
    "    df.loc[missing_sex, \"SEX\"] = np.random.choice([\"M\", \"F\"], size=len(df[missing_sex]))\n",
    "    df.loc[missing_family, \"FAMILY\"] = np.random.choice(df_family[\"FAMILY\"], size=len(df[missing_family]), p=df_family[\"PERCENTAGE\"])\n",
    "    for el in idx[1:]:\n",
    "        df.loc[el, \"NAME\"] = \"Name\"+str(el)\n",
    "        df.loc[el, \"ID\"] = id+el\n",
    "        df.loc[el, \"VILLAGE\"] = village\n",
    "    df=df.dropna(thresh=4)\n",
    "    id=id+village_dict[village]-1\n",
    "    \n",
    "    #df.to_csv(r\"projects_csv/complete/complete_\"+village+\".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the villages networks we can simply extract the data from the projects CSVs and substitute random generated rows with the ones belonging to projects set in that village. <br> \n",
    "In this way we will obtain a description of the situation for each village but, since what we want is a wider view on the project's influence on the community not only in villages but as a cross bridge between them, we ought to generate a complete network of Tulims's influence in the Pomerini zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/complete\")]\n",
    "villages = list()\n",
    "projects = list()\n",
    "for file in to_scan:\n",
    "    if file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0] in [\"Pomerini\", \"Mawambala\", \"Kitowo\", \"Khesa Mgagao\", \"Ukumbi\"]:\n",
    "        villages.append(file)\n",
    "    else:\n",
    "        projects.append(file)\n",
    "\n",
    "idx_dict = {\"Kitowo\": 1, \"Khesa Mgagao\": 1, \"Mawambala\": 1, \"Pomerini\": 1, \"Ukumbi\": 1}\n",
    "\n",
    "for project in projects:\n",
    "    df_project = pd.read_csv(project, encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "    project_name = project.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    idx = df_project.index.values.astype(int)\n",
    "    for el in idx:\n",
    "        village = df_project.loc[el, \"VILLAGE\"]\n",
    "        try:\n",
    "            df_village = pd.read_csv(\"projects_csv/complete/complete_\"+village+\".csv\", encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "            df_village.loc[idx_dict[village], \"NAME\"] = df_project.loc[el, \"NAME\"]\n",
    "            df_village.loc[idx_dict[village], \"VILLAGE\"] = df_project.loc[el, \"VILLAGE\"]\n",
    "            df_village.loc[idx_dict[village], \"PROJECT\"] = project_name\n",
    "            df_village.loc[idx_dict[village], \"AGE\"] = df_project.loc[el, \"AGE\"]\n",
    "            df_village.loc[idx_dict[village], \"SEX\"] = df_project.loc[el, \"SEX\"]\n",
    "            df_village.loc[idx_dict[village], \"FAMILY\"] = df_project.loc[el, \"FAMILY\"]\n",
    "            df_village.loc[idx_dict[village], \"START\"] = df_project.loc[el, \"START\"]\n",
    "            #df_village.to_csv(r\"projects_csv/complete/complete_\"+village+\".csv\")\n",
    "            idx_dict[village]+=1\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can mesh up those networks and create a wider one containing all information regarding projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/complete\")]\n",
    "villages = list()\n",
    "for file in to_scan:\n",
    "    if file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0] in [\"Pomerini\", \"Mawambala\", \"Kitowo\", \"Khesa Mgagao\", \"Ukumbi\"]:\n",
    "        villages.append(file)\n",
    "\n",
    "df_total=pd.DataFrame(columns=[\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"VILLAGE\"])\n",
    "\n",
    "for village in villages:\n",
    "    village_name = village.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    df = pd.read_csv(village, encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "    df_total = pd.concat([df_total, df], ignore_index=True)\n",
    "    missing_village=df_total[\"VILLAGE\"].isnull()\n",
    "    df_total.loc[missing_village, \"VILLAGE\"] = village_name\n",
    "\n",
    "#df_total.to_csv(r\"projects_csv/complete/whole_network.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can manually migrate files in a dedicated folder, namely \"villages\" and set the id as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df=df.set_index(\"ID\")\n",
    "    #df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating village networks\n",
    "Now, in order to create our network we need to set rules in order to discretely decide if two nodes are connected. <br>\n",
    "The main discriminants would be: \n",
    "<ol>\n",
    "<li><b>Being part of the same project</b>: this should be the most valuable kind of connection, of weight 3, since what we are trying to investigate are the connections created by the projects; </li>\n",
    "<li><b>Being part of the same family</b>: this kind of connection has definitely a heavier weight, since people living in the same family core should exchange information and positive or negative reinforcements that can weight on project's efficience; </li>\n",
    "<li><b>Being part of the same village</b></li>\n",
    "</ol>\n",
    "\n",
    "So now every node should present:\n",
    " <ol>\n",
    "<li>A number of connection of <b>weight 2</b> equal to the <b>number of participants in its project minus one</b> (itself)</li>\n",
    "<li>A number of connection of <b>weight 1</b> equal to the <b>number of people in its family core</b></li>\n",
    "</ol>\n",
    "\n",
    "Also in this phase it was possible to balance incoherences in family components distribution: simply after a first cycle of edges is created it is possible that some names are still present in the starting dataset.<br>\n",
    "This is because it is very difficult for families to be distributed so that at the end every component is in a core: the problem was solved by grouping leftovers as if they were a family core on their own of size equal to their quantity. Anyway it is impossible that this quantity exceeds the maximum amount of people per family, because otherway some of them would group together and lower again the quantity below 8, which is the maximum width of family cores.<br>\n",
    "This new family core is not only included as a set of edges but substituted to the previous in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df = df.sample(frac=1, ignore_index=True)\n",
    "\n",
    "    df_network = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "    df_node = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "\n",
    "    if file != \"projects_csv/villages\\\\whole_network.csv\":\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        idx = df.index.values.astype(int)\n",
    "        name_list = list()\n",
    "        for el in idx:\n",
    "            try:\n",
    "                n=1\n",
    "                for el_2 in idx:\n",
    "                    if n<=int(df.loc[el, \"FAMILY\"]):\n",
    "                        if df.loc[el, \"FAMILY\"] == df.loc[el_2, \"FAMILY\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"]:\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            family_count = int(df.loc[el, \"FAMILY\"])\n",
    "                            n+=1\n",
    "                            df = df.drop(el_2)\n",
    "                            idx = df.index.values.astype(int)\n",
    "                        else:\n",
    "                            continue     \n",
    "                    else:\n",
    "                        idx_last_edge = len(df_network)-1\n",
    "                        for i in range(family_count):\n",
    "                            target_count=family_count-(i+1)\n",
    "                            c=1\n",
    "                            for z in range(target_count):\n",
    "                                pointer_source = idx_last_edge-i\n",
    "                                pointer = pointer_source-c\n",
    "                                df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                c+=1\n",
    "                        df = df.drop(el)\n",
    "                        idx = df.index.values.astype(int)\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "\n",
    "        if len(df)>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx[:1]:\n",
    "                name_list.append(df.loc[el, \"ID\"])\n",
    "                for el_2 in idx[1:]:\n",
    "                    df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                    df_network = pd.concat([df_network, df_node], ignore_index = True)\n",
    "                    family_count = int(df.loc[el, \"FAMILY\"])\n",
    "                    name_list.append(df.loc[el_2, \"ID\"])\n",
    "                    df = df.drop(el_2)\n",
    "            idx_last_edge = len(df_network)-1\n",
    "            for i in range(family_count):\n",
    "                target_count=family_count-(i+1)\n",
    "                c=1\n",
    "                for z in range(target_count):\n",
    "                    pointer_source = idx_last_edge-i\n",
    "                    pointer = pointer_source-c\n",
    "                    df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                    df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                    c+=1\n",
    "            df = df.drop(el)\n",
    "        \n",
    "\n",
    "        df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        df_whole = pd.read_csv(\"projects_csv/villages\\\\whole_network.csv\", encoding=\"utf-8\")\n",
    "\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            if df.loc[el, \"ID\"] in name_list:\n",
    "                name = df.loc[el, \"ID\"]\n",
    "                df.loc[el, \"FAMILY\"] = len(name_list)\n",
    "                idx_name = df_whole.index[(df_whole[\"ID\"] == name) & (df_whole[\"VILLAGE\"] == file_name)]\n",
    "                df_whole.loc[idx_name, \"FAMILY\"] = len(name_list)\n",
    "        \n",
    "        #df.to_csv(r\"projects_csv/villages/complete_\"+file_name+\".csv\")\n",
    "\n",
    "        df_whole = df_whole.set_index('ID')\n",
    "        #df_whole.to_csv(r\"projects_csv/villages\\\\whole_network.csv\")\n",
    "\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            try:\n",
    "                project_count = 0\n",
    "                if df.loc[el, \"PROJECT\"] != \"Maji\":\n",
    "                    for el_2 in idx[el:]:\n",
    "                        if df.loc[el, \"PROJECT\"] == df.loc[el_2, \"PROJECT\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"]:\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            project_count +=1\n",
    "                            df = df.drop(el_2) \n",
    "                        else:\n",
    "                            continue        \n",
    "                    idx_last_edge = len(df_network)-1\n",
    "                    for i in range(project_count):\n",
    "                        target_count=project_count-(i+1)\n",
    "                        c=1\n",
    "                        for z in range(target_count):\n",
    "                            pointer_source = idx_last_edge-i\n",
    "                            pointer = pointer_source-c\n",
    "                            df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                            df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                            c+=1\n",
    "                    df = df.drop(el)\n",
    "            except Exception as e:\n",
    "                continue        \n",
    "\n",
    "        #df_network.to_csv(r\"projects_csv/networks/\"+file_name+\"_edges.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a file containing edges of the whole network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/networks\")]\n",
    "df_whole_edges = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "for file in to_scan:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df_whole_edges = pd.concat([df_whole_edges, df], ignore_index=True)\n",
    "\n",
    "df=pd.read_csv(\"projects_csv/villages\\\\whole_network.csv\", encoding=\"utf-8\")\n",
    "idx = df.index.values.astype(int)\n",
    "for el in idx:\n",
    "    try:\n",
    "        project_count = 0\n",
    "        if df.loc[el, \"PROJECT\"] != \"Maji\":\n",
    "            for el_2 in idx[el:]:\n",
    "                if df.loc[el, \"PROJECT\"] == df.loc[el_2, \"PROJECT\"] and df.loc[el, \"ID\"] != df.loc[el_2, \"ID\"] and df.loc[el, \"VILLAGE\"] != df.loc[el_2, \"VILLAGE\"]:\n",
    "                    df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                    df_whole_edges = pd.concat([df_whole_edges, df_node],ignore_index=True)\n",
    "                    project_count +=1\n",
    "                    df = df.drop(el_2) \n",
    "                else:\n",
    "                    continue        \n",
    "            idx_last_edge = len(df_whole_edges)-1\n",
    "            for i in range(project_count):\n",
    "                target_count=project_count-(i+1)\n",
    "                c=1\n",
    "                for z in range(target_count):\n",
    "                    pointer_source = idx_last_edge-i\n",
    "                    pointer = pointer_source-c\n",
    "                    df_node.loc[1,\"SOURCE\"] = df_whole_edges.loc[pointer_source, \"TARGET\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df_whole_edges.loc[pointer, \"TARGET\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 2\n",
    "                    df_whole_edges = pd.concat([df_whole_edges, df_node], ignore_index=True)\n",
    "                    c+=1\n",
    "            df = df.drop(el)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "df_whole_edges = df_whole_edges.drop_duplicates(keep='last')\n",
    "#df_whole_edges.to_csv(r\"projects_csv/networks/whole_edges.csv\")              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing left to do is clean the data as to process it in Gephi, by removing empty cells. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "for file in to_scan:\n",
    "    file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    try:\n",
    "        df= df.drop(\"Unnamed: 0\", axis=1)\n",
    "    except Exception:\n",
    "        df[[\"AGE\", \"FAMILY\", \"START\"]] = df[[\"AGE\", \"FAMILY\", \"START\"]].apply(pd.to_numeric)\n",
    "        df.to_csv(r\"projects_csv/networks/\"+file_name+\"_nodes.csv\")\n",
    "    df[[\"AGE\", \"FAMILY\", \"START\"]] = df[[\"AGE\", \"FAMILY\", \"START\"]].apply(pd.to_numeric)\n",
    "    #df.to_csv(r\"projects_csv/networks/\"+file_name+\"_nodes.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the new files and the nwtworks are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scan= [file for file in get_all_in_dir(\"projects_csv/networks\")]\n",
    "for file in to_scan:\n",
    "    file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\")\n",
    "    if file_name == \"edges\": \n",
    "        df = df.set_index(\"SOURCE\")\n",
    "    else:\n",
    "        df = df.set_index(\"ID\")\n",
    "    try: \n",
    "        df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "        #df.to_csv(file)\n",
    "    except Exception:\n",
    "        #df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "Now we need to clean data in this folder in order for Gephi to process it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = [file for file in get_all_in_dir(\"projects_csv/networks\")]\n",
    "for file in to_clean:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\") \n",
    "    for col in df.columns:\n",
    "        if col == \"ID\" or col == \"AGE\" or col == \"FAMILY\" or col == \"FRIENDS\" or col == \"WORK\" or col == \"WEIGHT\":\n",
    "            df[col] =  df[col].astype(int)\n",
    "        else:\n",
    "            df[col] =  df[col].astype(str)\n",
    "    df = df.set_index(df.columns[0])\n",
    "    #df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data regarding friends and working relatioship\n",
    " \n",
    "Another possible approach is to use literature on this topic to extract data regarding significant communities such as friendship and co-working. <br>\n",
    "\n",
    "In \"The role of strong-tie social networks in mediating food security of fish\n",
    "resources by a traditional riverine community in the Brazilian Amazon\" (2015, F. Merthes et al.) communities based on friendship have been find to fall in a range from 2 to 29 nodes connected; also work communities fall in a similar range, from 2 to 30. In the study it was found that, upon 915 that came down to 793 when considering overlappings, relationships, 177 were of friendship kind, 167 of working type and 571 based on kinship.<br>\n",
    "\n",
    "From this data, and the distribution of kinship relationship we have at disposal, we can easily recreate a model that follows the distribution evidentiated in this study and fills the gaps created by missing edge weights. This model should present nodes with edges strctured as follows:\n",
    " <ol>\n",
    "<li>A number of connection of <b>weight 2</b> equal to the <b>number of participants in its project minus one</b> (itself)</li>\n",
    "<li>A number of connection of <b>weight 1</b> equal to the <b>number of people in its family core</b> plus the <b>number of people in its friends and co-working community minus one</b> (itself)</li>\n",
    "</ol> \n",
    "\n",
    "Some small corrections were carried on in random assignation of value: irst of all children do not work, so their value of relationship through work was set to 0 and second no one has no friends so, in case available ties ended a rvalue of 1 was assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_scan = [file for file in get_all_in_dir(\"projects_csv/villages\")]\n",
    "\n",
    "for file in to_scan:\n",
    "    if file != \"projects_csv/villages\\\\whole_network.csv\":\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        df = pd.read_csv(\"projects_csv/networks/\"+file_name+\"_edges.csv\", encoding=\"utf-8\")\n",
    "        conversion_factor = df[\"WEIGHT\"].value_counts()[1]/571\n",
    "        friendship_ties = np.floor(177*conversion_factor)\n",
    "        working_ties = np.floor(167*conversion_factor)\n",
    "\n",
    "        df = pd.read_csv(file, encoding=\"utf-8\", index_col=\"Unnamed: 0\")\n",
    "        df = df.sample(frac=1, ignore_index=True)\n",
    "        df[\"FRIENDS\"] = np.nan\n",
    "        df[\"WORK\"] = np.nan\n",
    "        missing_friends = df[\"FRIENDS\"].isnull()\n",
    "        df.loc[missing_friends,'FRIENDS'] = np.random.choice(range(2, 29), size=len(df[missing_friends]))\n",
    "        missing_work = df[\"WORK\"].isnull()\n",
    "        df.loc[missing_work,'WORK'] = np.random.choice(range(2, 30), size=len(df[missing_work]))\n",
    "\n",
    "        df_network = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "        df_node = pd.DataFrame(columns=[\"SOURCE\", \"TARGET\", \"WEIGHT\"])\n",
    "        df_nodes = pd.DataFrame(columns = [\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"FRIENDS\", \"WORK\", \"VILLAGE\"])\n",
    "        to_add = pd.DataFrame(columns = [\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"FRIENDS\", \"WORK\", \"VILLAGE\"])\n",
    "\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            try:\n",
    "                n=1\n",
    "                for el_2 in idx[el:]: \n",
    "                    if n<=int(df.loc[el, \"FRIENDS\"]):\n",
    "                        if df.loc[el, \"FRIENDS\"] == df.loc[el_2, \"FRIENDS\"] and friendship_ties>0:\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = df.loc[el_2, \"FRIENDS\"]\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                            to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                            df_nodes = pd.concat([df_nodes, to_add])\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            friends_count = int(df.loc[el, \"FRIENDS\"])\n",
    "                            n+=1\n",
    "                            df = df.drop(el_2)\n",
    "                            idx = df.index.values.astype(int)\n",
    "                        elif friendship_ties<0:\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = 1\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                            to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                            df_nodes = pd.concat([df_nodes, to_add])\n",
    "                            to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                            to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                            to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                            to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                            to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                            to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                            to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                            to_add.loc[1, \"FRIENDS\"] = 1\n",
    "                            to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                            to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                            df_nodes = pd.concat([df_nodes, to_add])\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            df = df.drop(el_2)\n",
    "                            df = df.drop(el)\n",
    "                            break\n",
    "                    elif friendship_ties>0:\n",
    "                        to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                        to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                        to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                        to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                        to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                        to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                        to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                        to_add.loc[1, \"FRIENDS\"] = df.loc[el, \"FRIENDS\"]\n",
    "                        to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                        to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                        df_nodes = pd.concat([df_nodes, to_add])\n",
    "                        idx_last_edge = len(df_network)-1\n",
    "                        for i in range(friends_count):\n",
    "                            friendship_ties = friendship_ties-(friends_count-i)\n",
    "                            target_count=friends_count-(i+1)\n",
    "                            c=1\n",
    "                            for z in range(target_count):\n",
    "                                pointer_source = idx_last_edge-i\n",
    "                                pointer = pointer_source-c\n",
    "                                df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                c+=1\n",
    "                        df = df.drop(el)\n",
    "                        idx = df.index.values.astype(int)\n",
    "                        break\n",
    "                    else:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "\n",
    "        if len(df)>0 and friendship_ties>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx[:1]:\n",
    "                to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                to_add.loc[1, \"FRIENDS\"] = df.loc[el, \"FRIENDS\"]\n",
    "                to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                df_nodes = pd.concat([df_nodes, to_add])\n",
    "                for el_2 in idx[1:]:\n",
    "                    to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                    to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                    to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                    to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                    to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                    to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                    to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                    to_add.loc[1, \"FRIENDS\"] = df.loc[el, \"FRIENDS\"]\n",
    "                    to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                    to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                    df_nodes = pd.concat([df_nodes, to_add])\n",
    "\n",
    "                    df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                    df_network = pd.concat([df_network, df_node], ignore_index = True)\n",
    "                    friends_count = len(df)\n",
    "                    df = df.drop(el_2)\n",
    "\n",
    "                idx_last_edge = len(df_network)-1\n",
    "                for i in range(friends_count):\n",
    "                    friendship_ties = friendship_ties-(friends_count-i)\n",
    "                    target_count=friends_count-(i+1)\n",
    "                    c=1\n",
    "                    for z in range(target_count):\n",
    "                        pointer_source = idx_last_edge-i\n",
    "                        pointer = pointer_source-c\n",
    "                        df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                        df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                        df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                        df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                        c+=1\n",
    "                df = df.drop(el)\n",
    "        else:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx:\n",
    "                to_add.loc[1, \"ID\"] = df.loc[el, \"ID\"]\n",
    "                to_add.loc[1, \"NAME\"] = df.loc[el, \"NAME\"]\n",
    "                to_add.loc[1, \"PROJECT\"] = df.loc[el, \"PROJECT\"]\n",
    "                to_add.loc[1, \"AGE\"] = df.loc[el, \"AGE\"]\n",
    "                to_add.loc[1, \"SEX\"] = df.loc[el, \"SEX\"]\n",
    "                to_add.loc[1, \"FAMILY\"] = df.loc[el, \"FAMILY\"]\n",
    "                to_add.loc[1, \"START\"] = df.loc[el, \"START\"]\n",
    "                to_add.loc[1, \"FRIENDS\"] = 1\n",
    "                to_add.loc[1, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                df_nodes = pd.concat([df_nodes, to_add])\n",
    "                for el_2 in idx[el:el+1]:\n",
    "                    to_add.loc[1, \"ID\"] = df.loc[el_2, \"ID\"]\n",
    "                    to_add.loc[1, \"NAME\"] = df.loc[el_2, \"NAME\"]\n",
    "                    to_add.loc[1, \"PROJECT\"] = df.loc[el_2, \"PROJECT\"]\n",
    "                    to_add.loc[1, \"AGE\"] = df.loc[el_2, \"AGE\"]\n",
    "                    to_add.loc[1, \"SEX\"] = df.loc[el_2, \"SEX\"]\n",
    "                    to_add.loc[1, \"FAMILY\"] = df.loc[el_2, \"FAMILY\"]\n",
    "                    to_add.loc[1, \"START\"] = df.loc[el_2, \"START\"]\n",
    "                    to_add.loc[1, \"FRIENDS\"] = 1\n",
    "                    to_add.loc[1, \"WORK\"] = df.loc[el_2, \"WORK\"]\n",
    "                    to_add.loc[1, \"VILLAGE\"] = file_name\n",
    "                    df_nodes = pd.concat([df_nodes, to_add])\n",
    "                    df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                    df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                    df_node.loc[1,\"WEIGHT\"] = 1\n",
    "\n",
    "                    \t\n",
    "\n",
    "        #filling work\n",
    "\n",
    "        df = df_nodes      \n",
    "        df = df.sample(frac=1, ignore_index=True)\n",
    "\n",
    "        file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]\n",
    "        idx = df.index.values.astype(int)\n",
    "        for el in idx:\n",
    "            try:\n",
    "                n=1\n",
    "                for el_2 in idx[el:]:\n",
    "                    if n<=int(df.loc[el, \"WORK\"]): \n",
    "                        if df.loc[el, \"WORK\"] == df.loc[el_2, \"WORK\"] and working_ties>0:\n",
    "                            df_node.loc[1,\"SOURCE\"] = df.loc[el, \"ID\"]\n",
    "                            df_node.loc[1,\"TARGET\"] = df.loc[el_2, \"ID\"]\n",
    "                            df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                            df_network = pd.concat([df_network, df_node],ignore_index=True)\n",
    "                            work_count = int(df.loc[el, \"WORK\"])\n",
    "                            n+=1\n",
    "                            df = df.drop(el_2)\n",
    "                            idx = df.index.values.astype(int)     \n",
    "                    elif working_ties>0:\n",
    "                        idx_last_edge = len(df_network)-1\n",
    "                        for i in range(work_count):\n",
    "                            working_ties = working_ties-(work_count-i)\n",
    "                            target_count = work_count-(i+1)\n",
    "                            c=1\n",
    "                            for z in range(target_count):\n",
    "                                pointer_source = idx_last_edge-i\n",
    "                                pointer = pointer_source-c\n",
    "                                df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                c+=1\n",
    "                        df = df.drop(el)\n",
    "                        idx = df.index.values.astype(int)\n",
    "                        break\n",
    "                    else:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "\n",
    "        if len(df)>0 and working_ties>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx:\n",
    "                n=1\n",
    "                id_to_look = df.loc[el, \"ID\"]\n",
    "                df_nodes.loc[id_to_look, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                for el_2 in idx[1:]:\n",
    "                    if n<=int(df.loc[el, \"WORK\"]):\n",
    "                        id_to_look = df.loc[el_2, \"ID\"]\n",
    "                        df_nodes.loc[id_to_look, \"WORK\"] = df.loc[el, \"WORK\"]\n",
    "                        df = df.drop(el_2)\n",
    "                        n+=1\n",
    "                    else:\n",
    "                        work_count = df.loc[el, \"WORK\"]\n",
    "                        idx_last_edge = len(df_network)-1\n",
    "                        for i in range(work_count):\n",
    "                            working_ties = working_ties-(work_count-i)\n",
    "                            target_count=work_count-(i+1)\n",
    "                            c=1\n",
    "                            for z in range(target_count):\n",
    "                                pointer_source = idx_last_edge-i\n",
    "                                pointer = pointer_source-c\n",
    "                                df_node.loc[1,\"SOURCE\"] = df_network.loc[pointer_source, \"TARGET\"]\n",
    "                                df_node.loc[1,\"TARGET\"] = df_network.loc[pointer, \"TARGET\"]\n",
    "                                df_node.loc[1,\"WEIGHT\"] = 1\n",
    "                                df_network = pd.concat([df_network, df_node], ignore_index=True)\n",
    "                                c+=1\n",
    "                        df = df.drop(el)\n",
    "        elif len(df)>0:\n",
    "            idx = df.index.values.astype(int)\n",
    "            for el in idx:\n",
    "                id_to_look = df.loc[el, \"ID\"]\n",
    "                df_nodes.loc[id_to_look, \"WORK\"] = 0\n",
    "\n",
    "        df_nodes = df_nodes.drop_duplicates(keep=\"last\")\n",
    "        df_nodes = df_nodes.set_index(\"ID\")\n",
    "        #df_nodes.to_csv(r\"projects_csv/villages_comparison/nodes_\"+file_name+\".csv\")\n",
    "\n",
    "        df_network = df_network.set_index(\"SOURCE\")\n",
    "        #df_network.to_csv(r\"projects_csv/villages_comparison/edges_\"+file_name+\".csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "Now we can close up with the data cleaning: setting data type to columns and substituting blank values with spaces to make files readable from Gephi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clean = [file for file in get_all_in_dir(\"projects_csv/villages_comparison\")]\n",
    "for file in to_clean:\n",
    "    df = pd.read_csv(file, encoding=\"utf-8\") \n",
    "    df = df.dropna(thresh=2)\n",
    "    for col in df.columns:\n",
    "        if col == \"ID\" or col == \"AGE\" or col == \"FAMILY\" or col == \"FRIENDS\" or col == \"WORK\" or col == \"WEIGHT\" :\n",
    "            df[col] =  df[col].astype(int)\n",
    "        else:\n",
    "            df[col] =  df[col].astype(str)\n",
    "    df = df.set_index(df.columns[0])\n",
    "    #df.to_csv(file)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create complete network\n",
    "Now we can proceed to create the whole network of villages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole = pd.read_csv(\"projects_csv/networks\\\\whole_edges.csv\", encoding=\"utf-8\")\n",
    "df_whole_nodes = pd.DataFrame(columns = [\"ID\", \"NAME\", \"PROJECT\", \"AGE\", \"SEX\", \"FAMILY\", \"START\", \"FRIENDS\", \"WORK\", \"VILLAGE\"])\n",
    "to_append = [file for file in get_all_in_dir(\"projects_csv/villages_comparison\")]\n",
    "for file in to_append:\n",
    "    file_name = file.split(\"/\")[1].split(\"\\\\\")[1].split(\"_\")[0]\n",
    "    if file_name == \"edges\":\n",
    "        df_to_append = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        df_whole = pd.concat([df_whole,df_to_append], ignore_index=True)\n",
    "    else:\n",
    "        df_to_append = pd.read_csv(file, encoding=\"utf-8\")\n",
    "        df_whole_nodes = pd.concat([df_whole_nodes, df_to_append], ignore_index=True)\n",
    "\n",
    "df_whole = df_whole.set_index(\"SOURCE\")\n",
    "#df_whole.to_csv(r\"projects_csv/villages_comparison/network_edges.csv\")\n",
    "\n",
    "df_whole_nodes = df_whole_nodes.set_index(\"ID\")\n",
    "df_whole_nodes = df_whole_nodes.drop_duplicates(keep=\"last\")\n",
    "#df_whole_nodes.to_csv(r\"projects_csv/villages_comparison/network_nodes.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d603ae3e84bc2c7668b84db465d2afb033d38d826ce98f701f29ef4e883b1f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
